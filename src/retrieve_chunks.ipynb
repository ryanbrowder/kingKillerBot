{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10efef4b-0540-494a-a074-5691e32f3acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling manifest\n",
      "pulling f5074b1221da 4372811712 / 4372811712\n",
      "pulling 43070e2d4e53 11356 / 11356\n",
      "pulling 1ff5b64b61b9 799 / 799\n",
      "pulling ed11eda7790d 30 / 30\n",
      "pulling 1064e17101bd 487 / 487\n",
      "verifying sha256 digest\n",
      "writing manifest\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "resp = requests.post(\n",
    "    \"http://localhost:11434/api/pull\",\n",
    "    json={\"name\": \"mistral\"},\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for line in resp.iter_lines():\n",
    "    if not line:\n",
    "        continue\n",
    "    obj = json.loads(line.decode(\"utf-8\"))\n",
    "    # Print progress updates without spamming too hard\n",
    "    if \"status\" in obj:\n",
    "        if \"completed\" in obj and \"total\" in obj:\n",
    "            print(obj[\"status\"], obj[\"completed\"], \"/\", obj[\"total\"])\n",
    "        else:\n",
    "            print(obj[\"status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e152649-a249-4b94-9f07-a2aa3c6d5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/ryanbrowder/Documents/Projects/kingKillerBot\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Ensure we're running from project root\n",
    "ROOT = Path.cwd()\n",
    "if ROOT.name == \"src\":\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "os.chdir(ROOT)\n",
    "print(\"Working directory:\", Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3a78fe-47ff-4ba8-8960-8bb362176653",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_CODE = \"NOTW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a55575-7954-48f6-929d-1ad066374ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- Paths (root-relative) ---\n",
    "INDEX_PATH = Path(\"data/index/NOTW.faiss\")\n",
    "META_PATH  = Path(\"data/index/NOTW_meta.jsonl\")\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "TOP_K = 60  # retrieve more than we need, then filter\n",
    "\n",
    "def load_metadata(path: Path):\n",
    "    rows = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "def retrieve(\n",
    "    query: str,\n",
    "    max_chapter: int,\n",
    "    top_k: int = 80,\n",
    "    min_results: int = 12,\n",
    "    max_top_k: int = 500,\n",
    "    debug: bool = False\n",
    "):\n",
    "    index = faiss.read_index(str(INDEX_PATH))\n",
    "    meta = load_metadata(META_PATH)\n",
    "\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "    q_emb = model.encode(\n",
    "        [query],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "\n",
    "    debug_rows = []\n",
    "    results = []\n",
    "\n",
    "    k = top_k\n",
    "    while True:\n",
    "        scores, indices = index.search(q_emb, k)\n",
    "\n",
    "        results = []\n",
    "        debug_rows = []\n",
    "\n",
    "        for rank, (score, idx) in enumerate(zip(scores[0], indices[0]), start=1):\n",
    "            row = meta[idx]\n",
    "\n",
    "            passes = row.get(\"chapter\", 10**9) <= max_chapter\n",
    "            if debug:\n",
    "                preview = row.get(\"text\", \"\")[:250].replace(\"\\n\", \" \")\n",
    "                debug_rows.append({\n",
    "                    \"rank\": rank,\n",
    "                    \"idx\": int(idx),\n",
    "                    \"score\": float(score),\n",
    "                    \"chapter\": row.get(\"chapter\"),\n",
    "                    \"passes_chapter_filter\": passes,\n",
    "                    \"preview\": preview\n",
    "                })\n",
    "\n",
    "            if passes:\n",
    "                r = dict(row)\n",
    "                r[\"score\"] = float(score)\n",
    "                r[\"idx\"] = int(idx)\n",
    "                results.append(r)\n",
    "\n",
    "        # sort safe results\n",
    "        results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "        # ‚úÖ stop if we have enough safe chunks OR we‚Äôve searched deep enough\n",
    "        if len(results) >= min_results or k >= max_top_k:\n",
    "            break\n",
    "\n",
    "        # otherwise search deeper\n",
    "        k = min(k * 2, max_top_k)\n",
    "\n",
    "    if debug:\n",
    "        dbg = {\n",
    "            \"query\": query,\n",
    "            \"max_chapter\": max_chapter,\n",
    "            \"min_results\": min_results,\n",
    "            \"final_k\": k,\n",
    "            \"returned_after_filter\": len(results),\n",
    "            \"rows\": debug_rows\n",
    "        }\n",
    "        return results, dbg\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f228d814-751e-46ef-8ca7-f3f2b151672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import hashlib\n",
    "\n",
    "# -------------------------\n",
    "# Formatting / helpers\n",
    "# -------------------------\n",
    "def format_context(chunks, max_chars=3000, per_chunk_chars=450, max_chunks=6):\n",
    "    context_parts = []\n",
    "    used = 0\n",
    "    count = 0\n",
    "\n",
    "    for c in chunks:\n",
    "        if count >= max_chunks:\n",
    "            break\n",
    "\n",
    "        text = (c.get(\"text\") or \"\").strip()\n",
    "        if len(text) > per_chunk_chars:\n",
    "            text = text[:per_chunk_chars].rstrip() + \"‚Ä¶\"\n",
    "\n",
    "        score = c.get(\"score\", None)\n",
    "        score_str = f\"{score:.3f}\" if isinstance(score, (int, float)) else \"n/a\"\n",
    "        tag = \"expanded\" if c.get(\"expanded\") else \"chunk\"\n",
    "\n",
    "        block = f\"[Chapter {c.get('chapter')}] ({tag}, score={score_str})\\n{text}\"\n",
    "\n",
    "        if used + len(block) + 2 > max_chars:\n",
    "            break\n",
    "\n",
    "        context_parts.append(block)\n",
    "        used += len(block) + 2\n",
    "        count += 1\n",
    "\n",
    "    return \"\\n\\n\".join(context_parts).strip()\n",
    "\n",
    "\n",
    "def _normalize(txt: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (txt or \"\").strip()).lower()\n",
    "\n",
    "\n",
    "def _fingerprint(txt: str) -> str:\n",
    "    t = _normalize(txt)\n",
    "    core = (t[:600] + \"||\" + t[-600:]) if len(t) > 1200 else t\n",
    "    return hashlib.md5(core.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "def _chunk_id(c):\n",
    "    return (c.get(\"chapter\"), _fingerprint(c.get(\"text\", \"\")))\n",
    "\n",
    "\n",
    "def merge_triplet(prev_c, c, next_c, max_chars=1400):\n",
    "    parts = []\n",
    "    for x in (prev_c, c, next_c):\n",
    "        if not x:\n",
    "            continue\n",
    "        t = (x.get(\"text\") or \"\").strip()\n",
    "        if t:\n",
    "            parts.append(t)\n",
    "\n",
    "    merged = \"\\n\\n\".join(parts).strip()\n",
    "    if len(merged) > max_chars:\n",
    "        merged = merged[:max_chars].rstrip() + \"‚Ä¶\"\n",
    "\n",
    "    out = dict(c)\n",
    "    out[\"text\"] = merged\n",
    "    out[\"score\"] = c.get(\"score\")\n",
    "    out[\"expanded\"] = True\n",
    "    return out\n",
    "\n",
    "\n",
    "_STOP = {\n",
    "    \"the\",\"and\",\"for\",\"with\",\"that\",\"this\",\"what\",\"why\",\"does\",\"did\",\"his\",\"her\",\"their\",\n",
    "    \"from\",\"into\",\"then\",\"than\",\"have\",\"has\",\"had\",\"not\",\"but\",\"are\",\"was\",\"were\",\"you\",\n",
    "    \"your\",\"they\",\"them\",\"who\",\"when\",\"where\",\"how\"\n",
    "}\n",
    "\n",
    "\n",
    "def _query_terms(q: str):\n",
    "    terms = re.findall(r\"[a-z']{3,}\", (q or \"\").lower())\n",
    "    return {t for t in terms if t not in _STOP}\n",
    "\n",
    "\n",
    "def _overlap_score(chunk_text: str, q_terms: set) -> int:\n",
    "    t = (chunk_text or \"\").lower()\n",
    "    return sum(1 for term in q_terms if term in t)\n",
    "\n",
    "\n",
    "def _expand_queries(question: str):\n",
    "    q = (question or \"\").strip()\n",
    "    return [q, f\"{q} explanation\", f\"{q} reason\"]\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Context packing\n",
    "# -------------------------\n",
    "def pack_for_context(chunks, q_terms, min_overlap=1, target=14, min_hits=4):\n",
    "    def split(threshold):\n",
    "        hit, miss = [], []\n",
    "        for c in chunks:\n",
    "            o = _overlap_score(c.get(\"text\", \"\"), q_terms)\n",
    "            (hit if o >= threshold else miss).append(c)\n",
    "        return hit, miss\n",
    "\n",
    "    hit, miss = split(min_overlap)\n",
    "\n",
    "    if len(hit) < min_hits and min_overlap > 0:\n",
    "        hit, miss = split(0)\n",
    "\n",
    "    return (hit + miss)[:target]\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main entry\n",
    "# -------------------------\n",
    "def ask(question: str, current_chapter: int, show_debug: bool = False):\n",
    "    def dbg(*args):\n",
    "        if show_debug:\n",
    "            print(*args)\n",
    "\n",
    "    expanded_queries = _expand_queries(question)\n",
    "    q_terms = _query_terms(\" \".join(expanded_queries))\n",
    "\n",
    "    alpha = 0.10\n",
    "    def _rank_score(c):\n",
    "        s = c.get(\"score\", 0.0) or 0.0\n",
    "        o = _overlap_score(c.get(\"text\", \"\"), q_terms)\n",
    "        return s + alpha * o\n",
    "\n",
    "    all_chunks = []\n",
    "    all_debug_rows = []\n",
    "    final_k_max = 0\n",
    "    returned_after_filter_sum = 0\n",
    "\n",
    "    for q in expanded_queries:\n",
    "        result = retrieve(\n",
    "            q,\n",
    "            max_chapter=current_chapter,\n",
    "            top_k=TOP_K,\n",
    "            min_results=25,\n",
    "            max_top_k=800,\n",
    "            debug=show_debug\n",
    "        )\n",
    "\n",
    "        if show_debug:\n",
    "            chunks, dbg_info = result\n",
    "            if dbg_info:\n",
    "                final_k_max = max(final_k_max, dbg_info.get(\"final_k\", 0) or 0)\n",
    "                returned_after_filter_sum += dbg_info.get(\"returned_after_filter\", 0) or 0\n",
    "                all_debug_rows.extend(dbg_info.get(\"rows\", [])[:30])\n",
    "        else:\n",
    "            chunks = result\n",
    "\n",
    "        all_chunks.extend(chunks or [])\n",
    "\n",
    "    dbg(f\"[DEBUG] multiquery final_k_max={final_k_max} | safe_after_filter_sum={returned_after_filter_sum}\")\n",
    "\n",
    "    if not all_chunks:\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"current_chapter\": current_chapter,\n",
    "            \"context\": \"\",\n",
    "            \"note\": \"No spoiler-safe context available.\",\n",
    "            \"debug\": None\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Dedup best-wins\n",
    "    # -------------------------\n",
    "    best = {}\n",
    "    for c in all_chunks:\n",
    "        cid = _chunk_id(c)\n",
    "        if cid not in best or _rank_score(c) > _rank_score(best[cid]):\n",
    "            best[cid] = c\n",
    "\n",
    "    deduped = sorted(best.values(), key=_rank_score, reverse=True)\n",
    "    dbg(\"[DEBUG] top10 deduped:\", [(c.get(\"chapter\"), round(c.get(\"score\") or 0, 3)) for c in deduped[:10]])\n",
    "\n",
    "    # -------------------------\n",
    "    # Expand anchors\n",
    "    # -------------------------\n",
    "    meta = load_metadata(META_PATH)\n",
    "\n",
    "    def _get_safe(i):\n",
    "        if 0 <= i < len(meta):\n",
    "            row = meta[i]\n",
    "            if row.get(\"chapter\", 10**9) <= current_chapter:\n",
    "                r = dict(row)\n",
    "                r[\"idx\"] = i\n",
    "                r[\"score\"] = None\n",
    "                return r\n",
    "        return None\n",
    "\n",
    "    expanded = []\n",
    "    for c in deduped[:12]:\n",
    "        if c.get(\"idx\") is not None:\n",
    "            expanded.append(merge_triplet(\n",
    "                _get_safe(c[\"idx\"] - 1),\n",
    "                c,\n",
    "                _get_safe(c[\"idx\"] + 1),\n",
    "                max_chars=1600\n",
    "            ))\n",
    "        else:\n",
    "            expanded.append(c)\n",
    "\n",
    "    # -------------------------\n",
    "    # Final dedupe (prefer expanded)\n",
    "    # -------------------------\n",
    "    final = {}\n",
    "    for c in expanded:\n",
    "        cid = _chunk_id(c)\n",
    "        if cid not in final or (\n",
    "            c.get(\"expanded\") and not final[cid].get(\"expanded\")\n",
    "        ):\n",
    "            final[cid] = c\n",
    "\n",
    "    final_chunks = sorted(final.values(), key=_rank_score, reverse=True)\n",
    "\n",
    "    dbg(\"[DEBUG] final_chunks top:\",\n",
    "        [(c.get(\"chapter\"), round(c.get(\"score\") or 0, 3), bool(c.get(\"expanded\")))\n",
    "         for c in final_chunks[:8]])\n",
    "\n",
    "    final_chunks = pack_for_context(\n",
    "        final_chunks,\n",
    "        q_terms,\n",
    "        target=max(14, 3 * 6)\n",
    "    )\n",
    "\n",
    "    context = format_context(final_chunks)\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"current_chapter\": current_chapter,\n",
    "        \"context\": context,\n",
    "        \"note\": \"\",\n",
    "        \"debug\": {\n",
    "            \"rows\": all_debug_rows,\n",
    "            \"final_k\": final_k_max,\n",
    "            \"returned_after_filter\": returned_after_filter_sum\n",
    "        } if show_debug else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71d1d6a-4892-44ed-bb6c-a94172eacbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question: str, current_chapter: int, context: str) -> dict:\n",
    "    system = f\"\"\"\n",
    "You are a spoiler-safe companion for The Kingkiller Chronicle.\n",
    "The user is currently at Chapter {current_chapter} of {BOOK_CODE}.\n",
    "\n",
    "Rules:\n",
    "- Do NOT use or imply knowledge from after Chapter {current_chapter}.\n",
    "- Use ONLY the provided context to answer. If context is insufficient, say so.\n",
    "- Be clear and direct. Base your answer strictly on the context. \n",
    "- If something is implied rather than stated, say so explicitly.\n",
    "- If the question depends on later chapters, say: \"I can‚Äôt answer that yet without spoilers.\"\n",
    "\"\"\".strip()\n",
    "\n",
    "    user = f\"\"\"\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Context (spoiler-safe excerpts up to Chapter {current_chapter}):\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return {\"system\": system, \"user\": user}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbf93d8f-e1ad-48d7-a31c-bc922319c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def ollama_chat(system: str, user: str, model: str = \"mistral\") -> str:\n",
    "    r = requests.post(\n",
    "        \"http://localhost:11434/api/chat\",\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system},\n",
    "                {\"role\": \"user\", \"content\": user},\n",
    "            ],\n",
    "            \"stream\": False,\n",
    "        },\n",
    "        timeout=120,\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"message\"][\"content\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6299d69-e3a3-44b1-9aac-026c7eb32dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def answer(question: str, current_chapter: int, model=\"mistral\"):\n",
    "    resp = ask(question, current_chapter=current_chapter)\n",
    "\n",
    "    if not resp.get(\"context\"):\n",
    "        return {\n",
    "            \"answer\": \"I can‚Äôt answer that yet without spoilers (or I don‚Äôt have enough context from earlier chapters).\",\n",
    "            \"debug\": resp\n",
    "        }\n",
    "\n",
    "    prompt = build_prompt(\n",
    "        resp[\"question\"],\n",
    "        resp[\"current_chapter\"],\n",
    "        resp[\"context\"]\n",
    "    )\n",
    "\n",
    "    model_answer = ollama_chat(prompt[\"system\"], prompt[\"user\"], model=model)\n",
    "\n",
    "    retrieved_chapters = sorted({\n",
    "        int(c) for c in re.findall(r\"\\[Chapter (\\d+)\\]\", resp[\"context\"])\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"answer\": model_answer,\n",
    "        \"debug\": {\n",
    "            \"retrieved_chapters\": retrieved_chapters,\n",
    "            \"context_chars\": len(resp[\"context\"]),\n",
    "            \"model\": model\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b307398-7160-48a6-b13f-9499d74b82a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "STATE = {\n",
    "    \"book\": \"NOTW\",\n",
    "    \"chapter\": 9,\n",
    "    \"model\": \"mistral\",\n",
    "    \"debug\": False,\n",
    "    \"show_sources\": True,\n",
    "}\n",
    "\n",
    "def _md(s: str):\n",
    "    display(Markdown(s))\n",
    "\n",
    "def _banner():\n",
    "    _md(\n",
    "        f\"\"\"\n",
    "## üç∫ The Waystone Companion\n",
    "<small>\n",
    "Book: {STATE['book']} &nbsp;‚Ä¢&nbsp;\n",
    "Chapter: {STATE['chapter']} &nbsp;‚Ä¢&nbsp;\n",
    "Model: {STATE['model']}\n",
    "</small>\n",
    "\n",
    "> *It was night again. The Waystone Inn lay in silence.*\n",
    "---\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "def _help():\n",
    "    _md(\n",
    "        \"\"\"\n",
    "**Commands**\n",
    "- `/chapter N` ‚Äî set spoiler boundary\n",
    "- `/model NAME` ‚Äî set local model\n",
    "- `/status` ‚Äî show current settings\n",
    "- `/debug on|off` ‚Äî toggle debug\n",
    "- `/sources on|off` ‚Äî toggle sources\n",
    "- `/help` ‚Äî show commands\n",
    "- `/quit` ‚Äî leave the Waystone\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "def _status():\n",
    "    _md(\n",
    "        f\"\"\"\n",
    "**Status**\n",
    "- üìñ Book: `{STATE['book']}`\n",
    "- üìò Chapter: `{STATE['chapter']}`\n",
    "- ü§ñ Model: `{STATE['model']}`\n",
    "- üß™ Debug: `{STATE['debug']}`\n",
    "- üß© Sources: `{STATE['show_sources']}`\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "def _parse_cmd(q: str):\n",
    "    parts = q.strip().split()\n",
    "    return parts[0].lower(), parts[1:]\n",
    "\n",
    "def _kvothe_wrap(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return \"*Kvothe is quiet for a moment, then shakes his head.*\"\n",
    "\n",
    "    return (\n",
    "        \"_Kvothe rests his forearms on the bar, voice low and even:_\\n\\n\"\n",
    "        f\"{text}\"\n",
    "    )\n",
    "\n",
    "def chat():\n",
    "    _banner()\n",
    "    _help()\n",
    "\n",
    "    while True:\n",
    "        q = input(\"üü© You: \").strip()\n",
    "        if not q:\n",
    "            continue\n",
    "\n",
    "        # Commands\n",
    "        if q.startswith(\"/\"):\n",
    "            cmd, args = _parse_cmd(q)\n",
    "\n",
    "            if cmd in {\"/quit\", \"/exit\"}:\n",
    "                _md(\"*The fire crackles softly as the room settles back into silence.*\")\n",
    "                break\n",
    "\n",
    "            if cmd == \"/help\":\n",
    "                _help()\n",
    "                continue\n",
    "\n",
    "            if cmd == \"/status\":\n",
    "                _status()\n",
    "                continue\n",
    "\n",
    "            if cmd == \"/chapter\":\n",
    "                try:\n",
    "                    STATE[\"chapter\"] = int(args[0])\n",
    "                    _md(f\"‚úÖ Chapter set to **{STATE['chapter']}**\")\n",
    "                except Exception:\n",
    "                    _md(\"‚ö†Ô∏è Usage: `/chapter 37`\")\n",
    "                continue\n",
    "\n",
    "            if cmd == \"/model\":\n",
    "                if not args:\n",
    "                    _md(\"‚ö†Ô∏è Usage: `/model mistral`\")\n",
    "                else:\n",
    "                    STATE[\"model\"] = \" \".join(args)\n",
    "                    _md(f\"‚úÖ Model set to **{STATE['model']}**\")\n",
    "                continue\n",
    "\n",
    "            if cmd == \"/debug\":\n",
    "                if not args or args[0].lower() not in {\"on\", \"off\"}:\n",
    "                    _md(\"‚ö†Ô∏è Usage: `/debug on` or `/debug off`\")\n",
    "                else:\n",
    "                    STATE[\"debug\"] = (args[0].lower() == \"on\")\n",
    "                    _md(f\"‚úÖ Debug set to **{STATE['debug']}**\")\n",
    "                continue\n",
    "\n",
    "            if cmd == \"/sources\":\n",
    "                if not args or args[0].lower() not in {\"on\", \"off\"}:\n",
    "                    _md(\"‚ö†Ô∏è Usage: `/sources on` or `/sources off`\")\n",
    "                else:\n",
    "                    STATE[\"show_sources\"] = (args[0].lower() == \"on\")\n",
    "                    _md(f\"‚úÖ Sources set to **{STATE['show_sources']}**\")\n",
    "                continue\n",
    "\n",
    "            _md(\"‚ö†Ô∏è Unknown command. Type `/help`.\")\n",
    "            continue\n",
    "\n",
    "        # Normal question\n",
    "        out = answer(q, current_chapter=STATE[\"chapter\"], model=STATE[\"model\"])\n",
    "        ans = out.get(\"answer\", \"\").strip()\n",
    "        dbg = out.get(\"debug\", {}) or {}\n",
    "\n",
    "        _md(f\"### üü¶ Kvothe\\n{_kvothe_wrap(ans)}\")\n",
    "\n",
    "        if STATE[\"show_sources\"] and dbg.get(\"retrieved_chapters\") is not None:\n",
    "            _md(f\"<small>üìå Sources: `{dbg.get('retrieved_chapters')}`</small>\")\n",
    "\n",
    "        if STATE[\"debug\"] and dbg:\n",
    "            _md(\n",
    "                f\"<small>üß™ debug ‚Äî context_chars: `{dbg.get('context_chars')}` | model: `{dbg.get('model')}`</small>\"\n",
    "            )\n",
    "\n",
    "        _md(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ed42a4-c54c-48a5-9c6f-a705036a0d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üç∫ The Waystone Companion\n",
       "<small>\n",
       "Book: NOTW &nbsp;‚Ä¢&nbsp;\n",
       "Chapter: 9 &nbsp;‚Ä¢&nbsp;\n",
       "Model: mistral\n",
       "</small>\n",
       "\n",
       "> *It was night again. The Waystone Inn lay in silence.*\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Commands**\n",
       "- `/chapter N` ‚Äî set spoiler boundary\n",
       "- `/model NAME` ‚Äî set local model\n",
       "- `/status` ‚Äî show current settings\n",
       "- `/debug on|off` ‚Äî toggle debug\n",
       "- `/sources on|off` ‚Äî toggle sources\n",
       "- `/help` ‚Äî show commands\n",
       "- `/quit` ‚Äî leave the Waystone\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üü© You:  where is the waystone inn?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üü¶ Kvothe\n",
       "_Kvothe rests his forearms on the bar, voice low and even:_\n",
       "\n",
       "From the context provided, it is not explicitly stated where the Waystone Inn is located. However, in Chapter 1 (expanded), it is mentioned that if there had been a wind, it would have come from the trees outside the inn and brushed down the road, implying that the inn is situated along some sort of road or path. In Chapter 3 (expanded), Bast brings something in from outside to the bar, suggesting that the Waystone Inn has an outdoor area as well. However, without further context or information, I cannot provide a more specific location for the Waystone Inn."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<small>üìå Sources: `[0, 1, 3]`</small>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üü© You:  why is bast upset with kote?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üü¶ Kvothe\n",
       "_Kvothe rests his forearms on the bar, voice low and even:_\n",
       "\n",
       "Bast is upset with Kote because Kote left him a note saying he had gone out without informing Bast about his plans. This incident happened in Chapter 5 when Kote returned to the Waystone Inn late at night with Chronicler's limp body. Bast was concerned and angry that Kote did not inform him before leaving, especially since they were shorthanded due to the absence of their hired man and the eldest son who went to fight the rebels in Menat. In Chapter 1, we learn that Bast is responsible for teaching Kote's apprentice, Celum Tinture, but it seems Kote has been neglecting his lessons lately, which might also contribute to Bast's frustration with him. However, the primary reason for Bast's upset in Chapter 5 is due to Kote's sudden disappearance without proper communication."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<small>üìå Sources: `[1, 3, 5]`</small>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üü© You:  tell me about the interactions with the scrael\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üü¶ Kvothe\n",
       "_Kvothe rests his forearms on the bar, voice low and even:_\n",
       "\n",
       "In Chapter 1, it's revealed that Carter, one of the patrons at Kote's inn, was attacked by a scraeling, a fearsome creature that is not normally found in the world where the story takes place. The interaction between Bast (Kvothe's familiar) and Kote suggests that this event has caused some concern, as indicated by Bast's \"cracked mask\" of an easy smile falling away. However, the details about the scraeling attack or its aftermath are not elaborated upon in these chapters."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<small>üìå Sources: `[1, 4, 6, 7]`</small>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üü© You:  tell me about the interactions with the scraeling\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üü¶ Kvothe\n",
       "_Kvothe rests his forearms on the bar, voice low and even:_\n",
       "\n",
       "In the provided context, there are no interactions with scraelings mentioned. The Kingkiller Chronicle does feature scraelings, monstrous creatures from the Chronicler's stories that Kvothe (Kote) knows about but has not encountered yet. They serve as a significant element in the series, but they have not been introduced in the chapters provided so far."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<small>üìå Sources: `[1, 4, 6, 7]`</small>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üü© You:  what do we know about the chandrian?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üü¶ Kvothe\n",
       "_Kvothe rests his forearms on the bar, voice low and even:_\n",
       "\n",
       "In the provided context from The Kingkiller Chronicle up to Chapter 9, the Chandrian are not directly mentioned or described. However, there are hints that suggest their presence:\n",
       "\n",
       "1. Taborlin, who is known for his magical abilities, fell, and it is implied he may have fallen because of the Chandrian (Chapter 1). The Chandrian are feared entities that can hunt down and kill magic users.\n",
       "2. In Chapter 7, Chronicler mentions interviewing Oren Velciter, who sought him out. Oren Velciter is a legendary figure known for his tales about the Chandrian, implying their importance in the story's world.\n",
       "3. The fear of the Chandrian might be related to the \"dangerous stuff\" Kote mentions in Chapter 9, which could be an antidote against their poisonous touch (implied but not confirmed)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<small>üìå Sources: `[1, 3, 7, 9]`</small>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üü© You:  /exit\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*The fire crackles softly as the room settles back into silence.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade12b3-c1cb-4574-bda1-3cf119dcabdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
